# 02-13记一个奇怪的现象（关于分词和词性标注）
* 我们使用出现在“恭王府”文档中的一句话作为例子
~~~~
1851年，恭亲王奕訢成为宅子的主人，恭王府的名称也因此得来。
~~~~
## THULAC
* 首先我们使用THULAC，对这句话同时进行分词和词性标注。
~~~~
thu1.cut("1851年，恭亲王奕訢成为宅子的主人，恭王府的名称也因此得来。")
~~~~
* 结果如下：
~~~~
[['1851年', 't'], ['，', 'w'], ['恭亲', 'np'], ['王奕訢', 'np'], ['成为', 'v'], ['宅子', 'n'], ['的', 'u'], ['主人', 'n'], ['，', 'w'], ['恭王府', 'ns'], ['的', 'u'], ['名称', 'n'], ['也', 'd'], ['因此', 'c'], ['得', 'v'], ['来', 'v'], ['。', 'w']]
~~~~
* 显然在这里，“恭亲王奕訢”分词时出现了错误。
* 接着，使用THULAC仅仅对“奕訢”这一个词，进行词性标注
~~~~
thu1.cut("奕訢")
~~~~
* 结果如下：
~~~~
[['奕訢', 'v']]
~~~~
* 对“奕訢”这个人名的词性也标注错了

## LTP
* 接着使用LTP，LTP是用不同的模型按顺序分别进行“分词”和“词性标注”功能的，在这里我们向LTP的分词模型中，加入我们用户自定义的词汇列表
，这样就可以防止分词时，把一个实体名词分开了，即不会出现，上述THULAC分词时，将“恭亲王奕訢”分为：“恭亲”和“王奕訢”了。
* 加载模型
~~~~
'''LTP模型目录'''
default_model_dir = 'D:\python-file\knowledge_extraction-master-tyz\\ltp_data_v3.4.0\\'  
'''加载分词模型'''
segmentor = Segmentor()
user_dict = "source\\user.txt"
segmentor_flag = segmentor.load_with_lexicon(os.path.join(default_model_dir, 'cws.model'), user_dict)
'''加载词性标注模型'''
postagger = Postagger()
postag_flag = postagger.load(os.path.join(default_model_dir, 'pos.model'))
~~~~
* 进行分词
~~~~
words = segmentor.segment("1851年，恭亲王奕訢成为宅子的主人，恭王府的名称也因此得来。")
~~~~
* 结果如下：
~~~~
['1851年', '，', '恭亲王', '奕訢', '成为', '宅子', '的', '主人', '，', '恭王府', '的', '名称', '也', '因此', '得', '来', '。']
~~~~
* 从分词的结果看来，完全正确
* 进行词性标注
~~~~
poss = postagger.postag(words)
~~~~
* 结果如下：
~~~~
['nt', 'wp', 'n', 'v', 'v', 'n', 'u', 'n', 'wp', 'n', 'u', 'n', 'd', 'c', 'v', 'v', 'wp']
~~~~
* 根据对应关系可以看出，在一句话的词性标注中，将“奕訢”标注成了 动词v
* 我们再用LTP对“奕訢”单独进行词性标注
~~~~
postagger.postag(["奕訢"])[0]
~~~~
* 结果如下：
~~~~
nh
~~~~
* 结果正确

## 总结
综上，针对于“1851年，恭亲王奕訢成为宅子的主人，恭王府的名称也因此得来。”这一句话，和“奕訢”这一个词，得到一下奇怪的结论
1. 用THULAC   
*a.* 对一整句话进行词性标注----->分词错误
*b.* 对单独一个词进行词性标注----->词性标注错误
2. 用LTP   
*a.* 对一整句话进行词性标注----->分词正确，词性标注错误
*b.* 对单独一个词进行词性标注----->词性标注正确